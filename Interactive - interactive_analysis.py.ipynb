{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import GenerationConfig\n",
    "from setup import setup_model_and_sae\n",
    "from experiment import run_multiple_experiments\n",
    "from visualization import visualize_generation_activations, visualize_experiment_results\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52c92cf0-f169-4045-8adb-dcc8afc52371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model, tokenizer, and SAE...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0708f6028055437d8319e35731a1bacc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from setup import setup_model_and_sae\n",
    "from tqdm import tqdm\n",
    "print(\"Initializing model, tokenizer, and SAE...\")\n",
    "model_state = setup_model_and_sae()\n",
    "print(\"Initialization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64df9fdd-b08d-4c92-a333-0c6301ab719c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses: 100%|██████████| 25/25 [00:19<00:00,  1.26it/s]\n"
     ]
    }
   ],
   "source": [
    "config = GenerationConfig.precise()\n",
    "\n",
    "# Clear GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Clean up previous variables if they exist\n",
    "for var in ['gen_acts', 'gen_texts', 'tokens', 'results', 'fig']:\n",
    "    if var in locals() or var in globals():\n",
    "        exec(f'del {var}')\n",
    "\n",
    "# Set your prompt\n",
    "prompt = \"Answer the following question and provide your reasoning for the answer: \\\n",
    "Q: What will happen if a ball is thrown at a wall very fast? \\\n",
    "A:\"\n",
    "\n",
    "# Use tqdm for production runs\n",
    "with tqdm(total=config.num_runs, desc=\"Generating responses\") as pbar:\n",
    "    results = run_multiple_experiments(\n",
    "        prompt=prompt,\n",
    "        num_runs=config.num_runs,  \n",
    "        config=config,\n",
    "        model_state=model_state,\n",
    "        progress_callback=lambda: pbar.update(1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Visualize activations for first generation\n",
    "config = GenerationConfig.precise()\n",
    "\n",
    "print(\"\\nVisualizing activations for first generation...\")\n",
    "# Get the first generation's activations and text\n",
    "first_gen_acts = results.generation_acts[0]  # Get first run's activations\n",
    "first_gen_texts = []\n",
    "\n",
    "# Create list of texts at each step by tracking the incremental changes\n",
    "current_text = prompt\n",
    "for i in range(len(first_gen_acts)):\n",
    "    if i == 0:\n",
    "        first_gen_texts.append(current_text)  # Start with prompt\n",
    "    else:\n",
    "        # Get the new text generated at this step\n",
    "        new_text = results.all_texts[0]\n",
    "        # Only add text if it's different from the last one\n",
    "        if len(first_gen_texts) == 0 or new_text != first_gen_texts[-1]:\n",
    "            first_gen_texts.append(new_text)\n",
    "\n",
    "# Create activation visualizer with both original and encoded activations\n",
    "activation_data = {\n",
    "    'generation_acts': first_gen_acts,\n",
    "    'generated_texts': first_gen_texts,\n",
    "    'metadata': {\n",
    "        **results.metadata,\n",
    "        'model_name': results.model_state.model_name,\n",
    "        'sae_name': results.model_state.sae_name\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create and display activation visualizations\n",
    "print(\"\\nDisplaying activation visualizations (original MLP vs SAE-encoded)...\")\n",
    "activation_viz = visualization.GenerationActivationVisualizer(activation_data)\n",
    "activation_figures = activation_viz.create_figures()\n",
    "\n",
    "for fig in activation_figures:\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Visualize experiment results\n",
    "\n",
    "config = GenerationConfig.precise()\n",
    "\n",
    "# Create and display visualizations\n",
    "figures = visualize_experiment_results(results, config.num_runs)\n",
    "for fig in figures:\n",
    "    try:\n",
    "        fig.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Error displaying figure: {e}\")\n",
    "\n",
    "# Print detailed statistics\n",
    "print(\"\\nDetailed Statistics:\"\n",
    "print(f\"Average generation length: {results.avg_length:.2f} words\")\n",
    "print(f\"Unique token ratio: {results.unique_ratio:.2%}\")\n",
    "print(\"\\nStopping reasons:\")\n",
    "for reason, count in results.stopping_reasons.most_common():\n",
    "    print(f\"- {reason}: {count} times\")\n",
    "print(\"\\nMost common tokens:\")\n",
    "for token, count in results.token_frequencies.most_common(10):\n",
    "    print(f\"- '{token}': {count} times\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparsify",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
